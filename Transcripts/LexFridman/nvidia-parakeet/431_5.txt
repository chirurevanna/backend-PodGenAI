{
  "transcription": "what to you is the probability that superintelligent ai will destroy all human civilization what's the timeframe let's say a hundred years in the next hundred years so the problem of controlling a gi or superintelligence in my opinion is like a problem of creating a perpetual safety machine biology with perpetual motion machine it's impossible yeah we may succeed and do a good job with gpt five six seven but they just keep improving learning eventually self modifying interacting with the environment interacting with malevolent actors the difference between cybersecurity narrow ai safety and safety for generally for superintelligence is that we don't get a second chance with cybersecurity somebody hacks your account what's the big deal you get a new password new credit card you move on here if we're talking about existential risks you only get one chance so you're really asking me what are the chances that we'll create the most complex software ever on the first try with zero bugs and it will continue have zero bugs for a hundred years or more so there is an incremental improvement of systems leading up to agi to you it doesn't matter if we can keep those safe there's going to be one level of system at which you cannot possibly control it i don't think we so far have made any system safe at the level of capability they display they already have made mistakes we had accidents they've been drill broken i don't think there is a single large language model today which no one was successful at making making do something developers didn't intend it to do but there's a difference between getting it to do something unintended getting it to do something that's painful costly destructive and something that's destructive to the level of hurting billions of people or hundreds of millions of people billions of people or the entirety of human civilization that's a big leap exactly but the systems we have today have capability of causing x amount of damage so when they fail that's all we get if we systems capable of impacting all of humanity all of universe the damage is proportionate what to you are the possible ways that such kind of mass murder of humans can happen it's always a wonderful question so one of the chapters in my new book is about unpredictability i argue that we cannot predict what a smarter system will do so you're really not asking me how superintelligence will kill everyone you're asking me how i would do it and i think it's not that interesting i can tell you about a standard you know nanotech synthetic bionuclear superintelligence will come up with something completely new completely super we may not even recognize that as a possible path to achieve that goal so there's like an unlimited level of creativity in terms of how humans could be killed but you know we could still investigate possible ways of doing it not how to do it but the at the end what is the methodology that does it you know shutting off the power and then humans start killing each other maybe because the resources are really constrained that there and then there's the actual use of weapons like nuclear weapons or developing artificial pathogens viruses that kind of stuff we could still kind of think through that and defend against it right there's a ceiling to the creativity of mass murder of humans humans here right the options are limited they're limited by how imaginative we are if you are that much smarter that much more creative you are capable of thinking across multiple domains do novel research in physics and biology you may not be limited by those tools if squirrels were planning to kill humans they would have a set of possible ways of doing it but they would never consider things we can come up so you are you thinking about mass murder and destruction of human civilization are you thinking of with squirrels you put them in a zoo and they don't really know they're in a zoo if we just look at the entire set of undesirable trajectories majority of them are not going to be death most of them are going to be just like things like brave new world where you know the squirrels are fed dopamine and they're all like doing some kind of fun activity and the sort of the fire the soul of humanity is lost because of the drug that's fed to it or like literally in",
  "duration": 69.69890236854553
}