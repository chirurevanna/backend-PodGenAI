{
  "transcription": "you've had some strong statements technical statements about the future of artificial intelligence recently throughout your career actually but recently as well you've said that auto aggressive llms are not the way we're going to make progress towards superhuman intelligence these are the large language models like gpt for like llama two and threes and so on how do they work and why are they not going to take us all the way for a number of reasons the first is that there is a number of characteristics of intelligent behavior for example the capacity to understand the world understand the physical world the ability to remember and retrieve things persistent memory the ability to reason and the ability to plan those are four essential characteristics of intelligent systems or entities humans animals lnms can do none of those or they can only do them in a very primitive way and they don't really understand the physical world they don't really have persistent memory they can't really reason and they certainly can't plan and so you know if you expect a system to become intelligent just you know without having the possibility of doing those things you're making a mistake that is not to say that autoregressive llms are not useful they're certainly useful that they're not interesting that we can't build a whole ecosystem of applications around them of course we can but as a path towards human level intelligence they're missing essential components and then there is another tidbit or fact that i think is very interesting those lms are trained on enormous amounts of text basically the entirety of all publicly available text on the internet right that's typically on the order of ten to the thirteen tokens each token is typically two bytes so that's two ten to the thirteen bytes as training data it would take you or me a hundred and seventy thousand years to just read through this at eight hours a day so it seems like an enormous amount of knowledge right that those systems can accumulate but then you realize it's really not that much data if you talk to developmental psychologists and they tell you a four year old has been awake for sixteen thousand hours in his or her life and the amount of information that has reached the visual cortex of that child in four years is about ten to fifteen bytes and you can compute this by estimating that the optical nerve carry about twenty megabytes per second roughly and so ten to the fifteen bytes for a four year old versus two times ten to the thirteen bytes for a hundred and seventy thousand years worth of reading what that tells you is that through sensory input we see a lot more information than we than we do through language and that despite our intuition most of what we learn and most of our knowledge is through our observation and interaction with the real world not through language everything that we learn in the first few years of life and certainly everything that animals learn has nothing to do with language so it would be good to maybe push against some of the intuition behind what you're saying so it is true there's several orders of magnitude more data coming into the human mind much faster and the human mind is able to learn very quickly from that filter the data very quickly somebody might argue your comparison between sensory data versus language that language is already very compressed it already contains a lot more information than the bytes it takes to store them if you compare it to visual data so there's a lot of wisdom in language there's words and the way we stitch them together it already contains a lot of information so is it possible that language alone already has enough wisdom and knowledge in there to be able to from that language construct a world model an understanding of the world an understanding of the physical world that you're saying all lambs lack so it's a big debate among philosophers and also cognitive scientists like whether intelligence needs to be grounded in reality i'm clearly in the camp that yes intelligence cannot appear without some grounding in some reality it doesn't need to be",
  "duration": 63.91570258140564
}