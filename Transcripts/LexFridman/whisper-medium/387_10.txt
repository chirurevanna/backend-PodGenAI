{
  "transcription": " You mentioned something in a stream about the philosophical nature of time. So let's start with the wild question. Do you think time is an illusion? You know, I sell phone calls to Kama for a thousand dollars and some guy called me and like, you know, it's a thousand dollars. You can talk to me for half an hour and he's like, uh, yeah, okay so like Time doesn't exist and I really wanted to share this with you I'm like, oh, what do you mean? Time doesn't exist right? Like I think time is a useful model whether it exists or not, right? Like just quantum physics exists. Well, it doesn't matter. It's about whether it's a useful model to describe reality. Is time maybe compressive? Do you think there is an objective reality or is everything just useful models? Like underneath it all, is there an actual thing that we're constructing models for? I don't know. I was hoping you would know. I don't think it matters. I mean, this kind of connects to the models of constructive reality with machine learning, right? Sure. Like, is it just nice to have useful approximations of the world such that we can do something with it? So there are things that are real. Columnograph complexity is real. Yeah. Yeah. The compressive thing, math is real. Yeah. Should be a t-shirt. And I think hard things are actually hard. I don't think P equals NP. Ooh, strong words. Well, I think that's the majority. I do think factoring is in P, but. I don't think you're the person that falls the majority in all walks of life. So, but it's good. For that one I do. Yeah. In theoretical computer science, you, you're, you're one of the sheep. All right. But do you, uh, time is a useful model. Sure. Hmm. What were you talking about on the stream with time? Are you made of time? If I remembered half the things I said on stream, someday someone's going to make a model of all of that. And it's going to come back to haunt me. Someday soon? Yeah, probably. Would that be exciting to you or sad that there's a George Hots model? I mean, the question is when the George Hots model is better than George Hots. Like I am declining and the model is growing. What is the metric by which you measure better or worse in that if you're competing with yourself? Maybe you can just play a game where you have the George Hots answer and the George Hots model answer and ask which people prefer. People close to you or strangers? Either one. It will hurt more when it's people close to me, but both will be overtaken by the George Hottes model. of you. Especially when it's fine tuned to their preferences. Yeah, well, that's what we're doing in a relationship, right? We're just fine tuning ourselves, but we're inefficient with it because we're selfish and greedy and so on. Our language models can fine tune more efficiently, more selflessly. There's a Star Trek Voyager episode where, you know, Catherine Janeway lost in the Delta Quadrant makes herself a lover on the holodeck. And the lover falls asleep on her arm and he snores a little bit and Janeway edits the program to remove that. And then of course the realization is, wait, this person's terrible. It is actually all their nuances and quirks and slight annoyances that make this relationship worthwhile. But I don't think we're gonna realize that until it's too late. Well, I think a large language model could incorporate the flaws and the quirks and all that kind of stuff. Just the perfect amount of quirks and flaws to make you charming without crossing the line. Yeah, yeah. And that's probably a good like approximation of the, like the percent of time the language model should be a cranky or a, an asshole or jealous or all this kind of stuff. And of course it can and it will, but all that difficulty at that point is artificial. There's no more real difficulty. Okay. What's the difference between real and artificial? Artificial difficulty is difficulty that's like constructed or could be turned off with a knob. Real difficulty is like you're in the woods and you got to survive. So if something can not be turned off with a knob, it's real. Yeah, I think so. Or, I mean, you can't get out of this by smashing the knob with a hammer. I mean, maybe you kind of can, you know, into the wild when, you know, Alexander Supertramp, he wants to explore something that's never been explored before. But it's the 90s, everything's been explored. So he's like, well, I'm just not going to bring a map. Yeah. I mean, no, the metaphor of the knob? Well, that maybe is even scarier. Right? Like we already exist in a world of nature and nature has been fine-tuned over billions of years to have humans build something and then throw the knob away in some grand romantic gesture is horrifying. Do you think of us humans as individuals that are like born and die or is it, are we just all part of one living organism that is earth, that is nature? I don't think there's a clear line there. I think it's all kind of just fuzzy. I don't know. I mean, I don't think I'm conscious. I don't think I'm anything. I think I'm just a computer program. So it's all computation. Everything running in your head is just a, is a, is a, is computation. Everything running in the universe is computation, I think. I believe the extended church time thesis. Yeah, but it, there seems to be an embodiment to your particular computation. Like there's a consistency. Well, yeah, but I mean, models have consistency too. Yeah. Models that have been RLHF'd will continually say, you know, like, well, how do I murder ethnic minorities? Oh, well, I can't let you do that, Al. There's a consistency to that behavior. It's all RLHF. Like we are RLHF each other. We provide human feedback and thereby fine tune these little pockets of computation, but it's still unclear why that pocket of computation stays with you like for years. It just kind of falls, like you have this consistent set of physics, biology, whatever you call the neurons firing, the electrical signals, the mechanical signals, all of that, that seems to stay there. And it contains information, it stores information, and that information permeates through time and stays with you. There's like memory, to ask like the question about like, why, I don't know, like it's just some quirk of evolution, right? I don't think there's anything particularly special about where I ended up, where humans ended up. So, okay. We have human level intelligence. Would you call that AGI? Whatever we have? GI? Look, I actually, I don't really even like the word AGI, but general intelligence is defined to be whatever humans have. Okay. So why can GPT-12 not get us to AGI? Can we just like linger on that? If your loss function is categorical cross entropy, if your loss function is just try to maximize compression. I have a SoundCloud I rap and I tried to get chat GPT to help me write raps. And the raps that it wrote sounded like YouTube comment raps. You know, you can go on any rap beat online and you can see what people put in the comments. And it's the most like mid quality rap you can find. Is mid good or bad? Mid is bad. It's like mid. Every time I talk to you, I learn new words. Mid. Mid, yeah. Is it like basic? Is that what mid means? Kind of. It's like middle of the curve, right? Yeah, so there's like there's like I like that intelligence curve Yeah, and you have like the dumb guy the smart guy and then the mid guy actually being the mid guys the worst the smart guy is like I put all my money in Bitcoin the mid guys like you can't put money in Bitcoin. It's not real money And all of it is a genius meme that's's another interesting one. Memes, the humor, the idea, the absurdity encapsulated in a single image. And it just kind of propagates virally between all of our brains. I didn't get much sleep last night, so I'm very, I sound like I'm high, but I swear I'm not. Do you think we have ideas or ideas have us? I think that we're gonna get super scary memes once the AIs actually are superhuman. Ooh, the AI will generate memes? Of course. You think it'll make humans laugh?",
  "duration": 76.80184745788574
}