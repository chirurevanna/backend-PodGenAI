{
  "transcription": " Take me through the OpenAI board saga that started on Thursday, November 16th, maybe Friday, November 17th for you. That was definitely the most painful professional experience of my life and chaotic and shameful and upsetting and a bunch of other negative things. There were great things about it too and I wish it had not been in such an adrenaline rush that I wasn't able to stop and appreciate them at the time. I came across this old tweet of mine, or this tweet of mine from that time period, which was like it was like, you know, kind of going to your own eulogy, watching people say all these great things about you, and just like unbelievable support from people I love and care about. That was really nice. That whole weekend, I kind of like felt, with one big exception, I felt like a great deal of love and very little hate. Even though it felt like I just, I have no idea what's happening and what's gonna happen here and this feels really bad and there were definitely times I thought it was gonna be like one of the worst things to ever happen for AI safety. Well, I also think I'm happy that it happened relatively early. I thought at some point between when OpenAI started and when we created AGI, there was going to be something crazy and explosive that happened. But there may be more crazy and explosive things still to happen. It still, I think, helped us build up some resilience and be ready for more challenges in the future. But the thing you had a sense that you would experience is some kind of power struggle. The road to AGI should be a giant power struggle. Like the world should, well not should, I expect that to be the case. And so you have to go through that, like you said, iterate as often as possible, figuring out how to have a board structure, how to have organization, how to have the kind of people that you're working with, how to communicate all that in order to deescalate the power struggle as much as possible. Yeah. Passify it. But at this point, it feels like something that was in the past that was really unpleasant and really difficult and painful. But we're back to work and things are so busy and so intense that I don't spend a lot of time thinking about it. There was a time after, there was like this fugue state for kind of like the month after, maybe 45 days after, that was, I was just sort of like drifting through the days. Just in a middle of that. I just wanted to crawl into a cave and recover for a while. But now it's like we're just back to working on the mission. Well, it's still useful to go back there and reflect on board structures, on power dynamics, on how companies are run, the tension between research and product development and money and all this kind of stuff, so that you, who have a very high potential of building AGI, would do so in a slightly more organized, less dramatic way in the future. So there's value there to go, both the personal psychological aspects of you as a leader and also just the board structure and all this kind of messy stuff. Definitely learned a lot about structure and incentives and what we need out of a board. And I think that is, it is valuable that this happened now in some sense. I think this is probably not like the last high stress moment of opening up, but it was quite a high stress moment. My company very nearly got destroyed. And we think a lot about many of the other things we've got to get right for AGI, but thinking about how to build a resilient org and how to build a structure that will stand up to a lot of pressure in the world, which I expect more and more as we get closer, I think that's super important. Do you have a sense of how deep and rigorous the deliberation process by the board was? Can you shine some light on just human dynamics involved in situations like this? Was it just a few conversations and all of a sudden it escalates and why don't we fire Sam kind of thing? I think the board members were, are well-meaning people on the whole. And I believe that in stressful situations where people feel time pressure or whatever, people understandably make suboptimal decisions. And I think one of the challenges for OpenAI will be we're going to have to have a board and a team that are good at operating under pressure. Do you think the board had too much power? I think boards are supposed to have a lot of power. But one of the things that we did see is in most corporate structures, boards are usually answerable to shareholders. Sometimes people have like super voting shares or whatever. In this case, and I think one of the things with our structure that we maybe should have thought about more than we did is that the board of a nonprofit has, unless you put other rules in place, like quite a lot of power, they don't really answer to anyone but themselves. And there's ways in which that's good, but what we'd really like is for the board of OpenAI to answer to the world as a whole as much as that's a practical thing. So there's a new board announced. Yeah. There's, I guess, a new smaller board at first and now there's a new final board. Not a final board yet. We've added some. We'll add more. Added some. Okay. What is fixed in the new one that was perhaps broken in the previous one? The old board sort of got smaller over the course of about a year year it was nine and then it went on to six and then we couldn't agree on who to add and the board also I Think didn't have a lot of experienced board members and a lot of the new board members at open air have just have more experience as board members I I think that'll help. It's been criticized some of the people that are added to the board. I heard a lot of people criticizing the addition of Larry Summers, for example. What's the process of selecting the board like? What's involved in that? So, Brett and Larry were kind of decided in the heat of the moment over this like very tense weekend. And that weekend was like a real roller coaster. It was like a lot of ups and downs. And we were trying to agree on new board members that both sort of the executive team here and the old board members felt would be reasonable. Larry was actually one of their suggestions, the old board members. Brett, I think I had even previous to that weekend suggested, but he was busy and didn't want to do it and then we really needed help and wouldn't. We talked about a lot of other people too, but that was â€“ I felt like if I was going to come back, I needed new board members. I didn't think I could work with the old board again in the same configuration, although we then decided, and I'm grateful that Adam would stay, but we wanted to get to, we considered various configurations, decided we wanted to get to a board of three and had to find two new board members over the course of sort of a short period of time. So those were decided honestly without, you know, that's like you kind of do that on the battlefield. You don't have time to design a rigorous process then. For new board members since, new board members will add going forward, we have some criteria that we think are important for the board to have, different expertise that we want the board to have. Unlike hiring an executive where you need them to do one role well, the board needs to do a whole role of kind of governance and thoughtfulness well. And so one thing that Brett says, which I really like, is that we want to hire board members in slates, not as individuals one at a time. And thinking about a group of people that will bring nonprofit expertise, expertise of running companies, sort of good legal and governance expertise, that's kind of what we've tried to optimize for. So is technical savvy important for the individual board members? Not for every board member, but for certainly some you need that. That's part of what the board needs to do. So, I mean, the interesting thing that people probably don't understand about OpenAI, I certainly don't, is like all the details of running the business.",
  "duration": 48.265079498291016
}