{
  "transcription": "WHAT TO YOU IS THE PROBABILITY THAT SUPERINTELLIGENT AI WILL DESTROY ALL HUMAN CIVILIZATION WHAT'S THE TIME FRAME LET'S SAY A HUNDRED YEARS IN THE NEXT HUNDRED YEARS SO THE PROBLEM OF CONTROLLING A GI OR SUPERINTELLIGENCE IN MY OPINION IS LIKE A PROBLEM OF CREATING A PERPETUAL SAFETY MACHINE BY A KNOWLEDGE OF ITS PERPETUAL MOTION MACHINE IT'S IMPOSSIBLE YE WE MAY SUCCEED IN DO GOOD JOB WIH GIPI IFE SIX SEVEN BUT THEY JUST KEEP IMPROVING LEARNING EVENTUALLY SELF MODIFYING INTERACTING WITH THE ENVIRONMENT INTERACTING WITH MALEVOLENT ACTORS THE DIFFERENCE BETWEEN SIPER SECURITY NARROWA SAFETY AND SAFETY FOR GENERALLY I'VE A SUPER INTELLIGENCE IS THAT WE DON'T GET A SECOND CHANCE WITH SIPER SECURITY SOMEBODY HAKS YOUR ACCOUNT WHAT'S A BIG DEAL YOU GET A NEW PASSWORD NEW CREDIT CAR TO YOU MOVE ON HERE IF WE'RE TALKING ABOUT EXISTENTIAL RISKS YOU ONLY GET ONE CHANCE SO YOU'RE REALLY ASKING ME WHAT OFTHE CHANCES THAT WILL CREATE THE MOST COMPLEX AFT WERE EVER ON A FIRST STRIKE WITH ZERO BOGS AND IT WILL CONTINUE HAVE ZERO BOGS FOR A HUNDRED YEARS OR MORE SO THERE IS AN INCREMENTAL IMPROVEMENT OF SYSTEMS LEADING UP TO A G I TO YOU IT DOESN'T MATTER CAN KEEP THOSE SAFE THERE'S GOING TO BE ONE LEVEL OF SYSTEM AT WHICH YOU CANNOT POSSIBLY CONTROL IT I DON'T THINK WE SO FAR HAVE MADE ANY SYSTEM SAFE AT THE LEVEL OF CAPABILITY THEY DISPLAY THEY ALREADY HAVE MADE MISTAKES WE HAD ACCIDENTS THEY'VE BEEN JAIL BROKEN I DON'T THINK THERE IS A SINGLE LARGE LANGUAGE MODEL TO DAY WHICH NO ONE WAS SUCCESSFUL AT MAKING DO SOMETHING DEVELOPERS DIDN'T INTEND TO DO BUT THERE'S A DIFFERENCE BETWEEN GETTING IT TO DO SOMETHING UNINTENDED GETTING IT TO DO SOMETHING THAT'S PAINFUL COSTLY DESTRUCTIVE AND SOMETHING THAT'S DESTRUCTIVE TO THE LEVEL OF HURTING BILLIONS OF PEOPLE OR HUNDREDS OF MILLIONS OF PEOPLE BILLIONS OF PEOPLE OR THE ENTIRETY OF HUMAN CIVILIZATION THAT'S A BIG LEAP EXACTLY BUT THE SYSTEMS WE HAVE TO DAY HAVE CAPABILITY OF CAUSING EXCELLENT OF DAMAGE SO WHEN WE FAIL THAT'S ALL WE GET IF WE DEVELOPED SYSTEMS CAPABLE OF IMPACTING ALL OF HUMANITY ALL OF UNIVERSE THE DAMAGE IS PROPORTIONATE WHAT DO YOU ARE THE POSSIBLE WAYS THAT SUCH KIND OF MASS MURDER OF HUMANS CAN HAPPEN  IT'S ALWYS A WONDERFUL QUESTION SO ONE OF THE CHAPTERS IN MY NEW BOOK IS ABOUT UNPREDICTABILITY I ARGUE THAT WE CANNOT PREDICT WHAT A SMARTER SYSTEM WILL DO SO YOUTIL E NOT ASKING ME HOW SUPERINTELLIGENCE WILL KILL EVERYONE YOU'RE ASKING ME I WOULD DO IT AND I THINK IT'S NOT THAT INTERESTING I CAN TELL YOU ABOUT HE STANDARD ONO NONOTAC SYNTHETIC BIO NUCLEAR SUPER INTELLIGENCE WILL COME UP WITH SOMETHING COMPLETELY NEW COMPLETELY SUPER WE MAY NOT EVEN RECOGNIZE THAT AS A POSSIBLE PATH TO ACHIEVE THAT GOAL SERS LIKE A UNLIMITED LEVEL CREATIVITY IN TERMS OF HOW HUMANS COULD BE KILLED BUT YOU KNOW WE COULD STILL INVESTIGATE POSSIBLE WAYS OF ING IT NOT HOW TO DO IT BUT THE AT THE END WHAT IS THE METHODOLOGY THAT DOES IT YOU NOW SHUTTING OFF THE POWER AND THEN HUMANS START KILLING EACH OTHER MAYBE BECAUSE THEIR RESOURCES ARE REALLY CONSTRAINED TAT THEN THERE'S THE ACTUAL USE OF WEAPONS LIKE NUCLEAR WEAPONS OR DEVELOPING ARTIFICIAL PATHAGANS VIRUSES THAT KIND OF STUFF WE COULD STILL KIND OF THINK THROUGH THAT AND DEFEND AGAINST IT RIGHT THERE'S A CEALING TO THE CREATIVITY OF MASS MURDER HUMANS HERE THE OPTIONS ARELIMITED THEY ARE LIMITED BY HOW IMAGINATIVE WE ARE IF YOU ARE THAT MUCH SMARTER THAT MUCH MORE CREATIVE YOU ARE CAPABLE OF THINKING ACROSS MULTIPLE DOMAINS DO NOVEL RESEARCH IN PHYSICS AND BIOLOGY YOU MAY NOT BE LIMITED BY THOSE STOOLS IF SQUIRRELS WERE PLANNING TO KILL HUMANS THEY WOULD HAVE A SET OF POSSIBLE WAYS OF DOING IT BUT THEY WOULD NEVER CONSIDER THINGS WE CAN COME UP SO YOU ARE YOU THINKING ABOUT MASS MURDER N DESTRUCTIONAF HUMAN CIVILIZATION ARE YOU THINKING OF WHITH SQUIRRELS YOU PUT THEM IN A ZOO AND THEY DON'T REALLY KNOW THEY'RE IN A ZOO IF WE JUST LOOK AT THE ENTIRE SET OF UNDESIRABLE TRAJECTORIES MAJORITY OF THEM ARE NOT GOING TO BE DEATH MOST OF THEM ARE GOING TO BE JUST LIKE A THINGS LHIKE BRAVE NEW WORLD WHERE YOU KNOW THE SQUIRRELS ARE FED DOPMEN AND THEY'RE ALL LIKE DOING SOME KIND OF FUN ACTIVITY AND A SORT OF THE FIRE THE SOUL OF HUMANITY IS LOST BECAUSE OF THE DRUG THAT'S FED TO IT OR LIKE LITERALLY ZOO WE'RE IN A ZOO WE'RE DOING OUR THING WE'RE LIKE PLAYING A GAME OF SIMS AND THE ACTUAL PLAYERS PLAYING THAT GAME ARE AI SYSTEMS THOSE ARE ALL UNDESIRABLE BECAUSE A SORT OF THE FREE WILL THE FIRE OF HUMAN CONSCIOUSNESS IS DIMMED THROUGH THAT PROCESS BUT IT'S NOT KILLING HUMANS S THAT GAGUS AGAIN ABOUT THAT OR IS THE BIGGEST CONCERN LITERALLY THE EXTINCTIONS OF HUMANS I THINK ABOUT A LOT OF THINGS X RISK EXISTENTIAL RISK EVERYONE'S DEAD THERE IS S RISK SUFFERING RISKS WHERE EVERYONE WISHES THEY WERE DEAD WE HAVE ALSO IDEAS FOR EYE RISK IKIGI RISKS WHERE WE LOST EUR MEANING THE SYSTEMS CAN BE MORE CREATIVE THEY CAN DO ALL THER JOBS IT'S NOT OBVIOUS WHAT YOU HAVE TO CONTRIBUTE TO A WORLD WHERE SUPER INTELLIGENCE EXISTS OF COURSE YOU CAN HAVE ALL THE VARIANCE YOU MENTIONED WHERE WE ARE SAFE WE ARE KEPT ALIVE BUT WE ARE NOT IN CONTROL WE ARE NOT ING ANYTHING WE ARE LIKE ANIMALS AND S THERE IS AGAIN POSSIBILITIES WE CAN COME UP WITH AS VERY SMART HUMANS AND THEN POSSIBILITIES SOMETHING A THOUSAND TIMES SMARTER CAN COME UP WITH FOR REASONS WE CANNOT COMPREHEND OW LOST ES ARE DIGINTO EACH OF THOSE EX RISK AS RISK AND I RISK SO AKI LIKE LINGER AND I RISK WHAT IS THAT SO JAPANESE CONCEPT OF IKIGA YOU FIND SOMETHING WHICH ALLOWS YOU TO MAKE MONEY YOU ARE GOOD AT IT AND THE SOCIETY SAYS WE NEED IT SO LIKE YOU HAVE THE SASOME JOB YOUARE PODCASTER GIVES YOU A LOT OF MEANING YOU HAVE A GOOD LIFE I ASSUME YOU HAPPY THAT'S WHAT WE WANT MOST PEOPLE TO FIND TO HAVE FOR MANY INTELLECTUALS IT IS THEIR OCCUPATION WHICH GIVES THEM A LOT OF MEANING I'M A RESEARCHER PHILOSOPHER SCHOLAR THAT MEANS SOMETHING TO ME IN A WORLD WHERE AN ARTIST IS NOT FEELING APPRECIATED BECAUSE HIS ART IS JUST NOT COMPETITIVE WITH WHAT IS PRODUCED BY MACHINES OR WRITER OR SCIENTIST WILL LOSE A LOT OF THAT AND AT A LOWER LEVEL WE'RE TALKING ABOUT COMPLETE TECHNOLOGICAL UNEMPLOYMENT WE'RE NOT LOSING TEN PER CENT OF JOBS WE'RE LOSING ALL JOBS WHAT DO PEOPLE DO WITH ALL THAT FREE TIME WHAT HAPPENS THEN EVERYTHING SOCIETY IS BUILT ON IS COMPLETELY MODIFIED IN ONE GENE ON IT'S NOT A SLOW PROCESS WHER WE GET TO KIND O FIGURE OUT HOW TO LIVE THAT NEW LIFE STYLE BUT IT'S PRETTY QUICK IN THAT WORLD CAN'T HUMANS DO WHAT HUMANS CON ONLY DO WITH CHESS PLAY EACH OTHER HAVE TOURNAMENTS EVEN THE A SYSTEMS ARE FAR SUPERIOR AT THIS TIME IN CHESS SO WE JUST CREATE ARTIFICIAL GAMES OR FOR US THEY'RE REAL LIKE THE OLYMPICS AND WE DO ALL KINDS OF DIFFERENT COMPETITIONS AND HAVE FUN MAXIMIS THE FUN AND A LETE THE A I FOCUS ON THE PRODUCTIVITY IT'S AN OPTION I HAVE A PAPER WHERE I TRY TO SOLVE THE VOLUALIMENT PROBLEM FOR MULTIPLE AGENTS AND THE SOLUTION TO AVOID COMPROMISE IS TO GIVE EVERYONE A PERSONAL VIRTUAL UNIVERSE YOU CAN DO WHATEVER YOU WANT IN THAT WORLD YOU COULD BE KING YOU COULD BE SLAVE YOU DECIDE WHAT HAPPENS SO IT'S BASICALLY A GLORIFIED VIS GAME WERE YOU GET TO ENJOY YOURSELF AND SOME ONE ELSE TAKES CARE OF YOUR NEEDS AND THE SUBSTRAT ALLIMENT IS THE ONLY THING WE NEED TO SOLVE WE DON'T HAVE TO GET EIGHT BILLION HUMANS TO AGREE ON ANYTHING SOOK SO WAT WHY IS THAT NOT A LIKELY OUTCOME WHY CAN'T THE A SYSTEMS CREATE VIDIO GAMES FOR US TO LOSE OURSELVES IN EACH EACH WITH AN INDIVIDUAL VIDIO GAME UNIVERSE SOME PEOPLE SAY THAT'S WHAT HAPPENED WEN A SIMULATION AND WE'RE PLAYING THAT VIDIO GAME AND NOW WE'RE CREATING AH WHAT MAYBE WE'RE CREATING ARTIFICIAL THREATS FOR OURSELVES TO BE SCARED ABOUT ECAUSE FEAR IS REALLY EXCITING IT ALLOWS US TO PLAY THE VILIO GAME MORE MORE VIGOROUSLY AND SOME PEOPLE CHOOSE TO PLAY ON A MORE DIFFICULT LEVEL WITH MORE CONSTRAINTS SOME SAY YOU CAN SOON ENJOY THE GAME HIGH PRIVILEGED LEVEL ABSOLUTELY SO KE WHA WIS THAT PAPER MULTI AGENT VALULINMIT PERSONAL UNIVERSES PERSONAL UNIVERSES SO THAT'S ONE OF THE POSSIBLE OUTCOMES BUT WA WAWOLD IN GENERAL IS THE IDEA OF THE PAPER JUS LOOKING AT MULTIPLE AGENTS THAT'RE HUMAN A LIKE A HYBRID SYSTEM WHETHER ITS HUMANS IN THE EYES OR  LOOKING AT HUMANS OR JUST SO THIS INTELLIGENT AGENT IN ORDER TO SOLVE VALUALIMENT PROBLEM I'M TRYING TO FORMALIZE IT A LITTLE BETTER USUALLY WE'RE TALKING ABOUT GETTING AIS TO DO WHAT WE WANT WHICH IS NOT WELL DEFINED WE'RE TALKING ABOUT CREATOR OF A SYSTEM OWNER OF THAT A HUMANITY AS A WHOLE BUT WE DON'T AGREE ON MUCH THERE IS NO UNIVERSALLY ACCEPTED ETHICS MORAL",
  "duration": 10.694086790084839
}