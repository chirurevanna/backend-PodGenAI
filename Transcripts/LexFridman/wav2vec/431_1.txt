{
  "transcription": "WHAT TO YOU IS THE PROBABILITY THAT SUPERINTELLIGENT AI WILL DESTROY ALL HUMAN CIVILIZATION WHAT'S THE TIME FRAME LET'S SAY A HUNDRED YEARS IN THE NEXT HUNDRED YEARS SO THE PROBLEM OF CONTROLLING A GI OR SUPERINTELLIGENCE IN MY OPINION IS LIKE A PROBLEM OF CREATING A PERPETUAL SAFETY MACHINE BY A KNOWLEDGE OF ITS PERPETUAL MOTION MACHINE IT'S IMPOSSIBLE YE WE MAY SUCCEED IN DO GOOD JOB WIH GIPI IFE SIX SEVEN BUT THEY JUST KEEP IMPROVING LEARNING EVENTUALLY SELF MODIFYING INTERACTING WITH THE ENVIRONMENT INTERACTING WITH MALEVOLENT ACTORS THE DIFFERENCE BETWEEN SIPER SECURITY NARROWA SAFETY AND SAFETY FOR GENERALLY I'VE A SUPER INTELLIGENCE IS THAT WE DON'T GET A SECOND CHANCE WITH SIPER SECURITY SOMEBODY HAKS YOUR ACCOUNT WHAT'S A BIG DEAL YOU GET A NEW PASSWORD NEW CREDIT CAR TO YOU MOVE ON"
}