"You mentioned something in a stream about the philosophical nature of time. Let’s start with a wild question. Do you think time is an illusion? Time is an illusion. You know, I sell phone calls to Comma for a thousand dollars and some guy called me. It’s a thousand dollars. You can talk to me for half an hour. He is like, “Yeah, okay. Time doesn’t exist and I really wanted to share this with you.” I’m like, “Oh, what do you mean time doesn’t exist?” I think time is a useful model, whether it exists or not. Right. Does quantum physics exist? Well, it doesn’t matter. It’s about whether it’s a useful model to describe reality. Is time maybe compressive? Do you think there is an objective reality or is everything just useful models? Underneath it all is there an actual thing that we’re constructing models for? I don’t know. I was hoping you would know. I don’t think it matters. I mean, this connects to the models of constructive reality with machine learning, right? Sure. Is it just nice to have useful approximations of the world such that we can do something with it? There are things that are real. Complexity is real. Yeah. The compressive- Math. Math is real. Yeah. Should be a T-shirt. I think hard things are actually hard. I don’t think P equals NP. Ooh. Strong words. Well, I think that’s the majority. I do think factoring is in P. I don’t think you’re the person that follows the majority in all walks of life. For that one I do. Yeah. In theoretical computer science, you’re one of the sheep. All right. To you time is a useful model. Sure. What were you talking about on the stream about time? Are you made of time? If I remembered half the things I said on stream. Someday someone’s going to make a model of all of it and it’s going to come back to haunt me. Someday soon? Yeah, probably. Would that be exciting to you or sad that there’s a George Hotz model? I mean, the question is when the George Hotz model is better than George Hotz, like I am declining and the model is growing. What is the metric by which you measure better or worse in that, if you are competing with yourself? Maybe you can just play a game where you have the George Hotz answer and the George Hotz model answer and ask which people prefer. People close to you or strangers? Either one. It will hurt more when it’s people close to me, but both will be overtaken by the George Hotz model. It’d be quite painful. Loved ones, family members would rather have the model over for Thanksgiving than you or significant others would rather sext with the large language model version of you. Especially when it’s fine-tuned to their preferences. Yeah. Well, that’s what we’re doing in a relationship. We’re just fine-tuning ourselves, but we’re inefficient with it because we’re selfish and greedy and so on. Language models can fine-tune more efficiently, more selflessly. There’s a Star Trek Voyager episode where Kathryn Janeway lost in the delta quadrant makes herself a lover on the Holodeck, and the lover falls asleep on her arm and he snores a little bit. Janeway edits the program to remove that. Then of course the realization is, wait, this person’s terrible. It is actually all their nuances and quirks and slight annoyances that make this relationship worthwhile. I don’t think we’re going to realize that until it’s too late. Well, I think a large language model could incorporate the flaws and the quirks and all that kind of stuff. Just the perfect amount of quirks and flaws to make you charming without crossing the line. Yeah, and that’s probably a good approximation of the percent of time the language model should be cranky or an asshole or jealous or all this kind of stuff. Of course it can and it will. All that difficulty at that point is artificial. There’s no more real difficulty. What’s the difference between real and artificial? Artificial difficulty is difficulty that’s like constructed or could be turned off with a knob. Real difficulty is like you’re in the woods and you got to survive. If something cannot be turned off with a knob it’s real? Yeah, I think so. I mean, you can’t get out of this by smashing the knob with a hammer. I mean, maybe you can, Into the Wild when Alexander Supertramp, he wants to explore something that’s never been explored before, but it’s the nineties. Everything’s been explored. He’s like, “Well, I’m just not going to bring a map.” Yeah. I mean, no, you’re not exploring. You should have brought a map dude. You died. There was a bridge a mile from where you were camping. How does that connect to the metaphor of the knob? By not bringing the map, you didn’t become an explorer. You just smashed the thing. Yeah. Yeah. The difficulty is still artificial. You failed before you started. What if we just don’t have access to the knob? Well, that maybe is even scarier. We already exist in a world of nature, and nature has been fine-tuned over billions of years. To have humans build something and then throw the knob away in some grand romantic gesture is horrifying. Do you think of us humans as individuals that are born and die or are we just all part of one living organism that is earth, that is nature? I don’t think there’s a clear line there. I think it’s all kind of just fuzzy. I don’t know. I mean, I don’t think I’m conscious. I don’t think I’m anything. I think I’m just a computer program. It’s all computation, everything running in your head is just computation. Everything running in the universe is computation, I think. I believe the extended thesis. There seems to be an embodiment to your particular computation. There’s a consistency. Well, yeah, but I mean, models have consistency too. Yeah. Models that have been RLHF’d will continually say like, well, how do I murder ethnic minorities? Oh, well, I can’t let you do that, Hal. There’s a consistency to that behavior. It’s all RLHF. We RLHF each other. We provide human feedback and thereby fine-tune these little pockets of computation. It’s still unclear why that pocket of computation stays with you for years. You have this consistent set of physics, biology, whatever you call the neurons firing like the electrical signals, the mechanical signals, all of that that seems to stay there. It contains information. It stores information, and that information permeates through time and stays with you. There’s like memory, there’s like sticky. To be fair, a lot of the models we’re building today are very… Even RLHF is nowhere near as complex as the human loss function. Reinforcement learning with human feedback. When I talked about will GPT12 be AGI, my answer is no. Of course not. I mean, cross-entropy loss is never going to get you there. You need probably RL in fancy environments in order to get something that would be considered AGI-like. To ask the question about why? I don’t know. It’s just some quirk of evolution. I don’t think there’s anything particularly special about where I ended up, where humans ended up. Okay, we have human level intelligence. Would you call that AGI, whatever we have, GI? Look, actually, I don’t really even like the word AGI, but general intelligence is defined to be whatever humans have. Okay, so why can GPT-12 not get us to AGI? Can we just linger on that? If your loss function is categorical cross-entropy, if your loss function is just try to maximize compression. I have a SoundCloud I rap and I tried to get Chat-GPT to help me write raps and the raps that it wrote sounded like YouTube comment raps. You can go on any rap beat online and you can see what people put in the comments. It’s the most mid quality rap you can find. Is mid good or bad? Mid is bad. Mid is bad. It’s like mid. Every time I talk to you, I learn new words. Mid. Mid. Yeah. I was like, is it like basic? Is that what mid means? Kind of. It’s like middle of the curve, right? Yeah. There’s like that intelligence curve and you have the dumb guy, the smart guy, and then the mid guy. Actually being the mid guy is the worst. The smart guy is like I put all my money in Bitcoin. The mid guy is like, “You can’t put money in Bitcoin. It’s not real money.” All of it is a genius meme. That’s another interesting one. Memes, the humor, the idea, the absurdity encapsulated in a single image and it just propagates virally between all of our brains. I didn’t get much sleep last night, so I sound like I’m high. I swear I’m not. Do you think we have ideas or ideas have us? Memes. I think that we’re going to get super scary memes once the AIs actually are superhuman. You think AI will generate memes? Of course. You think it’ll make humans laugh?"