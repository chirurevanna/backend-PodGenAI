{
  "transcription": "Let's start with the big idea of scaling laws and the scaling hypothesis. What is it? What is its history, and where do we stand today? So I can only describe it as it, you know, as it relates to kind of my own experience. But I've been in the AI field for about 10 years, and it was something I noticed very early on. So I first joined the AI world when I was working at Baidu with Andrew ng in late 2014, which is almost exactly 10 years ago now. And the first thing we worked on was speech recognition systems. And in those days, I think deep learning was a new thing. It had made lots of progress, but everyone was always saying, we don't have the algorithms we need to succeed. You know, we're not. We're only matching a tiny, tiny fraction. There's so much we need to kind of discover algorithmically. We haven't found the picture of how to match the human brain and when, you know, in some ways, it was fortunate. I was kind of, you know, you can have almost beginner's luck, right? I was."
}