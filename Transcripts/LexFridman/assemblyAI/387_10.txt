{
  "transcription": "You mentioned something on a stream about the philosophical nature of time. So let's start with a wild question. Do you think time is an illusion? You know, I sell phone calls to comma for a thousand dollars. And some guy called me and like, you know, it's a thousand dollars. You can talk to me for, for half an hour. And he's like, yeah, okay, so like, time doesn't exist. And I really wanted to share this with you. I'm like, oh, what do you mean time doesn't exist? Right. Like, I think time is a useful model whether it exists or not. Right. Like, does quantum physics exist? Well, it doesn't matter. It's about whether it's a useful model to describe reality. Is time maybe compressive? Do you think there is an objective reality or is everything just useful models? Like, underneath it all, is there an actual thing that we're constructing models for? I don't know. I was hoping you would know. I don't think it matters. I mean, this kind of connects to the models of constructive reality with machine learning. Right? Sure. Like, is it just nice to have useful approximations of the world such that we can do something with it? So there are things that are real. Kolmograph. Complexity is real. Yeah. Yeah. The compressive math is real. Yeah. Should be a T shirt. And I think hard things are actually hard. I don't think P equals np. Ooh, strong words. Well, I think that's the majority. I do think factoring is in P, but I don't think you're the person that follows the majority in all walks of life, so. But it's good for that one. I do. Yeah. In theoretical computer science, you're one of the sheep. All right. But to you, time is a useful model. Sure. What were you talking about on the stream with time? Are you made of time? If I remembered half the things I said on stream, someday someone's going to make a model of all of it and it's going to come back to haunt me someday soon. Yeah, probably. Would that be exciting to you or sad that there's a George Hot's model? I mean, the question is when the George Hots model is better than George Hotz? Like, I am declining and the model is growing. What is the metric by which you measure better or worse in that if you're competing with yourself, maybe you can just play a game where you have the George Hots answer and the George Hots model answer and ask which people prefer, people close to you or strangers? Either one. It will hurt more when it's people close to me. But both will be overtaken by the George Hots model. It'd be quite painful, right? Loved ones family members would rather have the model over for Thanksgiving than you. Yeah. Or like significant others would rather sexed with the, with the large language model version of you, especially when it's fine tuned to their preferences. Yeah, well, that's what we're doing in a relationship, Right. We're just fine tuning ourselves, but we're inefficient with it because we're selfish in greedy and so on. Language models can fine tune more efficiently, more selflessly. There's a Star Trek Voyager episode where Katherine Janeway, lost in the Delta Quadrant, makes herself a lover on the holodeck and the lover falls asleep on her arm and he snores a little bit and Janeway edits the program to remove that. And then of course the realization is, wait, this person's terrible. It is actually all there nuances and quirks and slight annoyances that, that make this relationship worthwhile. But I don't think we're going to realize that until it's too late. Well, I think a large language model could incorporate the, the flaws and the quirks and all that kind of stuff. Just the perfect amount of quirks and floor flaws to make you charming without crossing the line. Yeah, yeah. And that's probably a good like, approximation of the, like the percent of time. The language model should be cranky or an asshole or jealous or all this kind of stuff. And of course it can and it will. But all that difficulty at that point is artificial. There's no more real difficulty. Okay, what's the difference between real and artificial? Artificial difficulty is difficulty that's like constructed or could be turned off with a knob. Real difficulty is like you're in the woods and you got to survive. So if something cannot be turned off with a knob is real? Yeah, I think so. Or I mean, you can't get out of this by smashing the knob with a hammer. I mean, maybe you kind of can, you know, into the wild when, you know, Alexander Supertramp, he wants to explore something that's never been explored before. But it's the nineties. Everything's been explored. So he's like, well, I'm just not going to bring a map. Yeah, I mean, no, you're, you're not exploring. You should have brought a map. Dude, you died. There was a bridge a mile from where you were camping. How does that connect to the metaphor of the knob? By not bringing the map. You didn't become an explorer. You just smashed the thing. Yeah, yeah. The art, the difficulty is still artificial. You failed before you started. What if we just don't have access to the knob? Well, that maybe is even scarier, right? Like we already exist in a world of nature and nature has been fine tuned over billions of years. To have humans build something and then throw the knob away in some grand romantic gesture is horrifying. Do you think of us humans as individuals that are like born and die? Or is it, are we just all part of one living organism? That is Earth, that is nature. I don't think there's a clear line there. I think it's all kind of just fuzzy. I don't know. I mean, I don't think I'm conscious. I don't think I'm anything. I think I'm just a computer program. So it's all computation. Everything running in your head is just a, is a, is computation. Everything running in the universe is computation. I think I believe the extended church time thesis. Yeah, but it, there seems to be an embodiment to your particular computation. Like there's a consistency. Well, yeah, but I mean, models have consistency too. Yeah, models that have been rlhfed will continually say, you know, like, well, how do I murder ethnic minorities? Oh, well, I can't let you do that, Hal. There's a consistency to that behavior. It's all RLHF. Like we all RLHF each other. We, we find, we provide human feedback and there that thereby fine tune these little pockets of computation. But it's still unclear why that pocket of computation stays with you like for years. It just kind of fall like you have this consistent set of physics, biology, what like whatever you call the, the neurons firing, like the electrical signals, the mechanical signals, all of that, that seems to stay there. And it contains information, it stores information and that information permeates through time and stays with you. There's like memory. There's like sticky. Okay, to be fair, like a lot of the models we're building today are very even. RLHF is nowhere near as complex as the human loss function. Reinforcement learning with human feedback. You know, when I Talked about Will GPT12 be AGI? My answer is no, of course not. I mean, cross entropy loss is never going to get you there. You need probably rl in fancy environments in order to get something that would be considered like AGI. Like so to ask like the question about like why. I don't know, like it's just some quirk of evolution. Right? I Don't think there's anything particularly special about where I ended up, where humans ended up. So, okay, we have human level intelligence. Would you call that AGI? Whatever. We have gi. Look, I Actually, I. I don't really even like the word AGI. But general intelligence is defined to be whatever humans have. Okay, so why can GPT12 not get us to AGI? Can we just like, linger on that? If your loss function is categorical cross entropy. If your loss function is. Just try to maximize compression. I have a soundcloud, I rap and I tried to get chat GPT to help me write raps. And the raps that it wrote sounded like YouTube comment raps. You know, you can go on any rap beat online and you can see what people put in the comments and it's the most like mid quality rap you can find. Is mid good or bad? Mid is bad. It's like mid. It's like every time I talk to you, I learn new words. Mid, mid. Yeah. I was like, is it. Is it like basic? Is that what mid means? Kind of. It's like. It's like middle of the curve, right? So there's like, there's like a. Like, see that intelligence curve? And you have like the dumb guy, the smart guy, and then the mid guy actually being the mid guy is the worst. The smart guy is like, I put all my money in bitcoin. The mid guy is like, you can't put money in bitcoin. It's not real money. And all of it is a genius meme. That's another interesting one. Memes. The humor, the idea, the absurdity encapsulated in a single image. And it just kind of propagates virally between all of our brains. I didn't get much sleep last night, so I'm very. I sound like I'm high. I swear I'm not. Do you think we have ideas or ideas have us? I think that we're going to get super scary memes once the AIs actually are superhuman. Ooh. Like the gay will generate memes. Of course you think it'll make humans laugh.",
  "duration": 20.055890560150146
}