{
  "transcription": "Perplexity is part search engine, part LLM. So how does it work, and what role does each part of that, the search and the LLM play in serving the final result? Perplexity is best described as an answer engine. So you ask it a question, you get an answer. Except the difference is all the answers are backed by sources. This is like how an academic writes a paper. Now that referencing part, the sourcing part is where the search engine part comes in. So you combine traditional search extract results relevant to the query the user asked, you read those links, extract the relevant paragraphs, feed it into an LLM. LLM means large language model, and that LLM takes the relevant paragraphs, looks at the query, and comes up with a well formatted answer with appropriate footnotes to every sentence."
}